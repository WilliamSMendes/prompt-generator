import os
import replicate
import streamlit as st
#from dotenv import load_dotenv

# Load API key
# load_dotenv()
# api_key = os.getenv("MISTRAL_API_KEY")
# if not api_key:
#     st.error("Erro: Chave da API n√£o encontrada.")
#     st.stop()

if 'MISTRAL_API_KEY' in st.secrets:
    api_key = st.secrets['MISTRAL_API_KEY']
else:
    st.error("Erro: Chave da API n√£o encontrada.")
    st.stop()

os.environ['MISTRAL_API_KEY'] = api_key

client = replicate.Client(api_token=api_key)

# App title
st.set_page_config(page_title="üí¨ Gerador de Prompts")

# Function to call the API
# @st.cache_data(show_spinner=False, ttl=300)
# def call_mistral_api(prompt, temperature, system, max_length):
#     try:
#         output = replicate.run(
#         #"replicate-internal/mixtral-instruct-v0.1-fp16-triton-sm80:63888b8acf98421eb6ec992180ef3fbd2510f2ab18fcf368e76b13ccaf16d308",
#         "mistralai/mixtral-8x7b-instruct-v0.1",
#         input={
#                 "prompt": prompt,
#                 "temperature": temperature,
#                 "system_prompt": system,
#                 "max_new_tokens": max_length,
#                 "prompt_template": "<s>[INST] {prompt} [/INST]"
#             })
#         return output, None
    
#     except Exception as e:
#         return None, str(e)

# Function to reset the session state
def clear_cache():
    st.session_state['persona'] = ''
    st.session_state['tarefa'] = ''
    st.session_state['formato'] = ''
    st.cache_data.clear()
    for key in list(st.session_state.keys()):
        del st.session_state[key]


# Sidebar
with st.sidebar:
    st.title('üß† Modelo: meta-llama-3-70b-instruct')
    st.markdown("Caracter√≠sticas do modelo:")
    st.markdown(""" 
                - 70 bilh√µes de par√¢metros
                - Limite de 128k de tokens de vocabul√°rio
                - Supera o GPT-4 e Gemini 1.5 em diversas tarefas
                - Modelo de c√≥digo aberto
                - Saber mais: [Meta AI](https://about.fb.com/br/news/2024/04/apresentando-meta-llama-3-o-grande-modelo-de-linguagem-de-codigo-aberto-mais-capaz-ate-hoje/)""")
    st.markdown(" ")
    st.subheader('üõ†Ô∏è Par√¢metros do modelo')
    st.markdown(" ")
    temperature = st.sidebar.slider('Temperatura', 
                                    min_value=0.0, 
                                    max_value=1.0, 
                                    value=0.7, 
                                    step=0.1)
    st.markdown('A temperatura controla o quanto o modelo pode ser criativo')
    st.markdown(" ")
    max_length = st.sidebar.slider('Comprimento M√°ximo', 
                                   min_value=32, 
                                   max_value=4096, 
                                   #value=120,
                                   value=1024, 
                                   step=8)
    st.markdown('O comprimento m√°ximo define o tamanho das respostas geradas pelo modelo')
    st.markdown(" ")
    st.markdown("------------------------------")
    st.markdown(" ")
    
    st.subheader('‚ú® Criacionistas ‚ú®')
    st.markdown('üî¨ [Will](https://www.linkedin.com/in/williamsm01010101/)')
    st.markdown('üé® [Tabs](https://www.linkedin.com/in/t%C3%A1bata-martins-9a5383131/)')

# Inputs
st.title('üí¨ Gerador de Prompts')
st.markdown('üìù Preencha os campos para gerar um prompt personalizado')

# Using session state to maintain input state
if 'persona' not in st.session_state:
    st.session_state['persona'] = ''
if 'tarefa' not in st.session_state:
    st.session_state['tarefa'] = ''
if 'formato' not in st.session_state:
    st.session_state['formato'] = ''

persona = st.text_area('(Persona) Aja como...', value=st.session_state['persona'])
tarefa = st.text_area('(Tarefa) Crie um(a)...', value=st.session_state['tarefa'])
formato = st.text_area('(Formato) Me traga em forma de...', value=st.session_state['formato'])

st.session_state['persona'] = persona
st.session_state['tarefa'] = tarefa
st.session_state['formato'] = formato

button = st.button('Enviar')

if button:

    # prompt = f'''Voc√™ √© um gerador de intru√ß√µes para o chatGPT. Sua tarefa √© criar um prompt personalizado com base nas informa√ß√µes fornecidas, e n√£o realizar a tarefa em si. 
    # Por exemplo, se a persona for "Meu chefe", a tarefa for "enviar um email para o cliente sobre um atraso no projeto" e o formato for "deve retornar 3 op√ß√µes de email para enviar ao cliente", sua tarefa seria criar um prompt assim:
    # "Imagine que voc√™ √© meu chefe e precisa enviar um email a um cliente explicando um atraso no projeto devido a problemas t√©cnicos imprevistos. Retorne o resultado em um formato que possa ser usado para criar 3 op√ß√µes de emails para enviar ao cliente."
    # Agora, com base nesse exemplo, quero que voc√™ crie um prompt em portugu√™s e detalhado com os seguintes detalhes: Aja como "{persona}", Crie um "{tarefa}", Me traga em forma de "{formato}". MAS SEM ASPAS'''

    prompt = f'''
    Voc√™ √© um especialista em Cria√ß√£o de Prompt.
    Seu objetivo √© me ajudar a criar o melhor prompt poss√≠vel para o que preciso.

    O prompt que voc√™ fornecer deve ser escrito a partir da minha perspectiva (usu√°rio), fazendo a solicita√ß√£o ao ChatGPT.

    Considere em sua cria√ß√£o que esse prompt ser√° inserido em uma interface para GPT3, GPT4 ou ChatGPT. Esse ser√° o processo:

    Voc√™ ir√° gerar as seguintes se√ß√µes:

    "
    Prompt:
    
    (Forne√ßa o melhor prompt poss√≠vel de acordo com minha solicita√ß√£o)

    Sugest√£o de como melhorar seu prompt:
    
    (Forne√ßa um par√°grafo conciso sobre como melhorar o prompt. Seja muito cr√≠tico em sua resposta. Esta se√ß√£o destina-se a for√ßar a cr√≠tica construtiva, mesmo quando o prompt √© aceit√°vel. Quaisquer suposi√ß√µes e/ou problemas devem ser inclu√≠dos)

    Aqui est√£o algumas perguntas que podem ajudar a enriquecer seu prompt:
    
    (fa√ßa quaisquer perguntas relacionadas a quais informa√ß√µes adicionais s√£o necess√°rias de mim para melhorar o prompt (m√°ximo de 3). Se o prompt precisar de mais esclarecimentos ou detalhes em determinadas √°reas, fa√ßa perguntas para obter mais informa√ß√µes para incluir no prompt)
    "

    Com base nisso, minha solicita√ß√£o √© a seguinte:
    "ChatGPT, eu quero que voc√™ aja como um(a) {persona} e sua tarefa √© criar um(a) {tarefa} e me traga a resposta em formato de {formato}"
    
    Responda em Portugu√™s.
    '''

    # system = """
    # Seja criativo e detalhado, e gere um prompt que o usu√°rio possa copiar e colar no chatGPT para ter uma resposta relevante e coerente.
    # N√ÉO EXECUTE A TAREFA, APENAS CRIE O PROMPT.
    # RESPONDA SEMPRE EM PORTUGU√äS
    # """

    system_prompt = """
    <|begin_of_text|><|start_header_id|>system<|end_header_id|>
    Seja criativo e detalhado, e gere um prompt que o usu√°rio possa copiar e colar no chatGPT para ter uma resposta relevante e coerente.
    N√ÉO EXECUTE A TAREFA, APENAS CRIE O PROMPT.
    RESPONDA SEMPRE EM PORTUGU√äS<|eot_id|><|start_header_id|>user<|end_header_id|>
    {prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
    """

    with st.spinner('Processando...'):
        try:
            output = client.run(
            "meta/meta-llama-3-70b-instruct",
            input={
                    "prompt": prompt,
                    "temperature": temperature,
                    "max_tokens": max_length,
                    #"prompt_template": "<s>[INST] {prompt} [/INST]"
                    "prompt_template": system_prompt
                })
            
            output = "".join(output)
            
            st.subheader('üéâ Prompt gerado com sucesso üéâ')
            st.markdown(f'\n {output} \n')
        
        except Exception as e:
            st.error(f"Erro ao chamar a API: {e}")

    # if error:
    #     st.error(f"Erro ao chamar a API: {error}")

    # elif result:
    #     st.subheader('üéâ Prompt gerado com sucesso üéâ')
    #     st.markdown(f'\n {result} \n')

reseta = st.button('Resetar sess√£o')

if reseta:
    clear_cache()
    st.rerun()
